# AI Agent Configuration

# LLM Configuration
llm:
  # Provider options: "ollama", "openai_like", or "mock"
  provider: "mock"

  # Model name
  model: "mock"

  # API Base URL
  api_base: "http://localhost:11434"

  # API Key (for OpenAI-like providers)
  api_key: ""

  # Temperature for generation (0.0 = deterministic, 1.0 = creative)
  temperature: 0.0

  # Top-p for nucleus sampling (0.0 - 1.0)
  top_p: 1.0

# Agent Configuration
agent:
  # Maximum number of tasks in a plan
  max_tasks: 50

  # Maximum conversation history messages
  max_history: 100

  # Timeout for task execution (seconds)
  task_timeout: 300

# Repository Configuration
repository:
  # Ignore these directories when scanning
  ignore_dirs:
    - ".git"
    - "__pycache__"
    - "node_modules"
    - ".venv"
    - "venv"
    - "dist"
    - "build"

  # File extensions to consider as code
  code_extensions:
    - ".py"
    - ".js"
    - ".ts"
    - ".tsx"
    - ".jsx"
    - ".java"
    - ".go"
    - ".rs"
    - ".cpp"
    - ".c"
    - ".h"

# Logging Configuration
logging:
  # Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  level: "INFO"

  # Log file path (leave empty to disable file logging)
  file: ""

  # Whether to log to console
  console: true
